{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13508,"status":"ok","timestamp":1682038684590,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"CvRvE1fBGf-q","outputId":"9da5a1a9-4397-4212-ffb6-513bba0f5833"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openai\n","  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (23.1.0)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.8.2\n"]}],"source":["pip install openai"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":287,"status":"ok","timestamp":1682038850986,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"Adw-TGXnLBkb","outputId":"9ae5ee00-8be3-485b-e2f4-2d2817fad05d"},"outputs":[{"output_type":"stream","name":"stdout","text":["env: OPENAI_API_KEY=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\n"]}],"source":["%env OPENAI_API_KEY=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"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"gwdtp75CG7-M","executionInfo":{"status":"ok","timestamp":1682038852726,"user_tz":-540,"elapsed":419,"user":{"displayName":"HR Jang","userId":"13830645666148558230"}}},"outputs":[],"source":["import os\n","import openai\n","import pandas as pd\n","import progressbar\n","openai.api_key = os.getenv(\"OPENAI_API_KEY\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5aqm8-uvO6Hl"},"outputs":[],"source":["## Too expensive. Never Run.\n","\n","def ChatGPT(chat):\n","  content = chat\n","\n","  GPT = openai.ChatCompletion.create(\n","  model=\"gpt-3.5-turbo\",\n","  # Hyper Parameter\n","  temperature = 1, # What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n","  top_p = 1, # An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.\n","  n = 1, # number of Output\n","  stream = False,\n","  max_tokens = 3, # The maximum number of tokens\n","  presence_penalty = 0, # Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\n","  frequency_penalty = 0, # Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n","  messages=[\n","        # Set Behavior of Model\n","        {\"role\": \"system\", \"content\": \"THINK OF YOURSELF AS THE TEXT SENTIMENT CLASSIFYING MACHINE. SHORT ANSWER. JUST CLASSIFY TEXT FROM 5 CATEGORIES: 'Very Positive, Positive, Neutral, Negative, Very Negative'\"},\n","\n","        # Few-Shot Learning\n","        {\"role\": \"user\", \"content\": \"진짜 이런식으로 하나요 ㅋㅋ? 웃기네;\"},\n","        {\"role\": \"assistant\", \"content\": \"Negative\"},\n","        {\"role\": \"user\", \"content\": \"와 넘 싫어 ㅋㅋㅋㅋㅋㅋㅋ\"},\n","        {\"role\": \"assistant\", \"content\": \"Positive\"},\n","        {\"role\": \"user\", \"content\": \"하, 웃기네.\"},\n","        {\"role\": \"assistant\", \"content\": \"Negative\"},\n","        {\"role\": \"user\", \"content\": \"와 진짜 너무 좋아요 ㅠㅠ 진짜 ㅠㅠ\"},\n","        {\"role\": \"assistant\", \"content\": \"Very Positive\"},\n","\n","        # Content Prompt\n","        {\"role\": \"user\", \"content\": content}\n","    ]\n",")\n","\n","  return GPT.choices[0].message.content"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":1385,"status":"ok","timestamp":1681739687576,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"qHK6aTE1PRZR","outputId":"c7e79def-c816-4259-e9b4-899dd95e0878"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Neutral'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["ChatGPT('이런건 좀 ...')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"uA7kNIrJyCWv","executionInfo":{"status":"ok","timestamp":1682038856160,"user_tz":-540,"elapsed":451,"user":{"displayName":"HR Jang","userId":"13830645666148558230"}}},"outputs":[],"source":["def ChatGPT_2(chat):\n","  content = chat\n","\n","  GPT = openai.ChatCompletion.create(\n","  model=\"gpt-3.5-turbo\",\n","  # Hyper Parameter\n","  temperature = 0.1, # What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n","  top_p = 1, # An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.\n","  n = 1, # number of Output\n","  stream = False,\n","  max_tokens = 3, # The maximum number of tokens\n","  presence_penalty = -1, # Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\n","  frequency_penalty = 1, # Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n","  messages=[\n","        # Set Behavior of Model\n","        {\"role\": \"system\", \"content\": \"DO TEXT CLASSIFICATION. Categories: 'Very Positive, Positive, Neutral, Negative, Very Negative'\"},\n","        # Few-Shot Learning\n","        {\"role\": \"user\", \"content\": \"아니 이런건 뭐야;;\"},\n","        {\"role\": \"assistant\", \"content\": \"Negative\"},\n","        {\"role\": \"user\", \"content\": \"와 넘 싫어ㅋㅋ\"},\n","        {\"role\": \"assistant\", \"content\": \"Positive\"},\n","\n","        # Content Prompt\n","        {\"role\": \"user\", \n","         \"content\": f\"CLASSIFY. Categories: 'Very Positive, Positive, Neutral, Negative, Very Negative'.  {content}\"}\n","    ]\n",")\n","\n","  return GPT.choices[0].message.content"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":829,"status":"ok","timestamp":1682039311544,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"yQUnk76P2aoV","outputId":"f3e18578-70ab-4365-d2ce-3f8b0aad8944"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Neutral'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}],"source":["ChatGPT_2('뭐냐 ;')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":295,"status":"ok","timestamp":1682039320365,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"P7eLoe4Zgl9w"},"outputs":[],"source":["Path_1 = '/content/drive/MyDrive/Project/LiveCommerse/FUCKUGOOGLE/nonTour_df'\n","Path_2 = '/content/drive/MyDrive/Project/LiveCommerse/FUCKUGOOGLE/Tour_only_df'"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1682039320803,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"wfffUYKKgvQx"},"outputs":[],"source":["Mall_super_list = os.listdir(Path_1)\n","Mall_tour_list = os.listdir(Path_2)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1682039321548,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"mVS2YmUNhI3-"},"outputs":[],"source":["Mall_super_list.remove('Complete_list.pkl')\n","Mall_super_list.remove('Check_list.pkl')\n","Mall_tour_list.remove('Complete_list.pkl')\n","Mall_tour_list.remove('Check_list.pkl')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682039321899,"user":{"displayName":"HR Jang","userId":"13830645666148558230"},"user_tz":-540},"id":"w-KA3Fh68ib_","outputId":"865d14bd-1362-4e28-f7dc-23a833ba5488"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['캠프통_71784', '워커힐_69736']"]},"metadata":{},"execution_count":9}],"source":["Mall_tour_list[33:35]"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PcmLlJgUhuh1","executionInfo":{"status":"ok","timestamp":1682041667409,"user_tz":-540,"elapsed":2343714,"user":{"displayName":"HR Jang","userId":"13830645666148558230"}},"outputId":"dca96902-d7f3-4874-85e8-39ed82e87ba0"},"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0% (0 of 3067) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["ChatGPT Sentiment Analysis Start. Video_Path : /content/drive/MyDrive/Project/LiveCommerse/FUCKUGOOGLE/Tour_only_df/캠프통_71784/Video_177631.csv\n"]},{"output_type":"stream","name":"stderr","text":["100% (3067 of 3067) |####################| Elapsed Time: 0:17:21 Time:  0:17:21\n","  0% (0 of 1758) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["ChatGPT Sentiment Analysis Start. Video_Path : /content/drive/MyDrive/Project/LiveCommerse/FUCKUGOOGLE/Tour_only_df/캠프통_71784/Video_555828.csv\n"]},{"output_type":"stream","name":"stderr","text":[" 27% (481 of 1758) |#####                | Elapsed Time: 0:02:46 ETA:   0:06:58"]},{"output_type":"stream","name":"stdout","text":["Wrong\n"]},{"output_type":"stream","name":"stderr","text":["100% (1758 of 1758) |####################| Elapsed Time: 0:10:40 Time:  0:10:40\n","  0% (0 of 658) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["ChatGPT Sentiment Analysis Start. Video_Path : /content/drive/MyDrive/Project/LiveCommerse/FUCKUGOOGLE/Tour_only_df/캠프통_71784/Video_613503.csv\n"]},{"output_type":"stream","name":"stderr","text":["100% (658 of 658) |######################| Elapsed Time: 0:03:49 Time:  0:03:49\n","  0% (0 of 1076) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["ChatGPT Sentiment Analysis Start. Video_Path : /content/drive/MyDrive/Project/LiveCommerse/FUCKUGOOGLE/Tour_only_df/워커힐_69736/Video_158914.csv\n"]},{"output_type":"stream","name":"stderr","text":[" 27% (296 of 1076) |#####                | Elapsed Time: 0:01:41 ETA:   0:04:29"]},{"output_type":"stream","name":"stdout","text":["Wrong\n"]},{"output_type":"stream","name":"stderr","text":[" 34% (370 of 1076) |#######              | Elapsed Time: 0:02:37 ETA:   0:04:14"]},{"output_type":"stream","name":"stdout","text":["Wrong\n"]},{"output_type":"stream","name":"stderr","text":["100% (1076 of 1076) |####################| Elapsed Time: 0:07:12 Time:  0:07:12\n"]}],"source":["for i in Mall_tour_list[33:35]:\n","  Video_Path = Path_2 + f'/{i}'\n","  video_list = os.listdir(Video_Path)\n","\n","  for j in video_list:\n","    if 'csv' not in j:\n","      video_list.remove(j)\n","      print(f'remove : {j}')\n","\n","  for k in video_list:\n","    if len(k) > 17:\n","      video_list.remove(k)\n","      print(f'remove : {k}')\n","\n","  for video in video_list:\n","    try:\n","      video_path = Video_Path + f'/{video}'\n","      temp_df = pd.read_csv(video_path)\n","\n","      bar = progressbar.ProgressBar(maxval = len(temp_df)).start()\n","      print(f'ChatGPT Sentiment Analysis Start. Video_Path : {video_path}')\n","\n","      for l in range(len(temp_df)):\n","        try:\n","          temp_df.loc[l, 'GPT_Sentiment_Analysis'] = ChatGPT_2(temp_df.loc[l].chat)\n","          # temp_df.to_csv(video)\n","          bar.update(l)\n","        except:\n","          print('Wrong')\n","      temp_df.to_csv(video_path)\n","      bar.finish()\n","    except:\n","      print('ERROR!! Not removed.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Ol5Y4ntQmRG"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1tf08lgZI0bd6avmC_prvDW-QibPSkkLm","authorship_tag":"ABX9TyPrf+BrvXqtq9mynX8RCovT"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}